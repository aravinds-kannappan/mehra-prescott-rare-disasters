{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef36dd9",
   "metadata": {},
   "source": [
    "This file replicates Tables 1 and 2. We credit Jaroslav Borovička for the baseline code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbdf9c6",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "We will use data on asset returns and consumption growth. Several considerations are important.\n",
    "\n",
    "* We need to agree on the length of the time period $t$. Typical period length for this type of problem would be a month, a quarter, or a year. Below, we consider quarterly frequency. This means that all quantities need to be downloaded or converted to quarterly frequency.\n",
    "\n",
    "* Because the theory applies to real quantities and data on asset returns typically come in nominal form, we will need to deflate them by an appropriate inflation index.\n",
    "\n",
    "* Since there are alternative time series for consumption growth, inflation, and many different types of available returns, appropriate choice of these quantities often involves considerable judgement.\n",
    "\n",
    "You can download all data below manually into a single spreadsheet which you use for pre-processing, and then load the prepared spreadsheet directly for the GMM estimation. Below, I conduct all the steps in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed3464",
   "metadata": {},
   "source": [
    "Import relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f4a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root package econutil imported.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "from io import BytesIO\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "\n",
    "# load econutil package with some frequently used functions\n",
    "import econutil as ec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5becb4a",
   "metadata": {},
   "source": [
    "### Consumption and inflation data from FRED\n",
    "\n",
    "The Federal Reserve Bank of St. Louis maintains a large database of economic time series data (FRED - Federal Reserve Economic Data).\n",
    "\n",
    "https://fred.stlouisfed.org/\n",
    "\n",
    "Every time series is identified by a unique series identifier. Python provides API functionality in the <b><tt>pandas_datareader</tt></b> package to directly download the time series if you know the identifiers, or you can browse the database to find suitable data.\n",
    "\n",
    "The theoretical moment conditions apply to real consumption. We could download nominal consumption expenditures and deflate them ourselves, or use one of the available real series. We do the latter. Here are some available series:\n",
    "\n",
    "- <b><tt>PCEC</tt></b>: Personal consumption expenditures in billions of USD, seasonally adjusted (https://fred.stlouisfed.org/series/PCEC). This series is in nominal dollars but the theoretical moments are expressed in real consumption units, so we would need to deflate it by the proper price index.\n",
    "\n",
    "- <b><tt>PCECC96</tt></b>: Personal consumption expenditures in billions of <b>chained 2017 USD</b>, seasonally adjusted (https://fred.stlouisfed.org/series/PCECC96). This series is already deflated to real terms. However, it expresses total consumption expenditures of the whole population, while the theory applies to an individual (even though representative) investor. We should therefore perhaps adjust for population growth, even though this will have negligible quantitative implications in our specific application.\n",
    "\n",
    "- <b><tt>A794RX0Q048SBEA</tt></b>: Personal consumption expenditures <b>per capita</b> in <b>chained 2017 USD</b>, seasonally adjusted (https://fred.stlouisfed.org/series/A794RX0Q048SBEA).\n",
    "\n",
    "- <b><tt>PCECTPI</tt></b>: Chain-type price index for personal consumption expenditures (https://fred.stlouisfed.org/series/PCECTPI). While we download consumption data already in real terms, we will need to deflate returns as well. Again, there are multiple price indices, the two most prominent ones being the Consumer Price Index (CPI), and the Personal Consumption Expenditures (PCE) Price Index, which are collected in alternative ways. We will use PCE to deflate returns, since the above consumption expenditures series are also deflated by PCE.\n",
    "\n",
    "As you can see, there is a range of choices to be made when engaging in empirical work, some of which requiring judgement calls. For example, the differences between aggregate consumption and consumption per capita, or between using the CPI or PCE price indices will not have dramatic impacts for our conclusions but may be substantial in other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4988c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal consumption PCEC, real personal consumption PCECC96,\n",
    "# real personal consumption per capita A794RX0Q048SBEA, PCE price index PCECTPI\n",
    "\n",
    "# myLoadDataFRED uses the pandas_reader.data.Reader function to download time series from FRED\n",
    "data_C = ec.LoadDataFRED(series=['PCEC','PCECC96','A794RX0Q048SBEA','PCECTPI'],transform='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944ed8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a YYYYQ (year, quarter) index for merging data with returns later\n",
    "data_C = data_C['orig'].reset_index()\n",
    "data_C['YYYYQ'] = data_C['DATE'].dt.year*10 + (data_C['DATE'].dt.month+2)//3\n",
    "data_C = data_C.drop(columns=['DATE'])\n",
    "\n",
    "# construct inflation time series ((P_{t}/P_{t-1}-1))\n",
    "data_C['infl'] = data_C['PCECTPI'] + float(\"nan\")\n",
    "data_C.loc[1:,'infl'] =(data_C['PCECTPI'][1:].values / data_C['PCECTPI'][0:-1].values - 1)\n",
    "\n",
    "# construct real consumption growth per capita ((C_t/C_{t-1}-1))\n",
    "data_C['gC'] = data_C['A794RX0Q048SBEA'] + float(\"nan\")\n",
    "data_C.loc[1:,'gC'] =(data_C['A794RX0Q048SBEA'][1:].values / data_C['A794RX0Q048SBEA'][0:-1].values - 1)\n",
    "data_C = data_C.drop(data_C.index[0])\n",
    "#data_C = data_C.drop(data_C.index[data_C.index > 20200])\n",
    "\n",
    "data_C = data_C.set_index('YYYYQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee31b8",
   "metadata": {},
   "source": [
    "### Returns data from Kenneth French's website\n",
    "\n",
    "Kenneth French maintains a large database of asset returns widely used as standard test returns in asset pricing applications. These emerged from his early work from Eugene Fama on factor based asset pricing.\n",
    "\n",
    "https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html\n",
    "\n",
    "We will be using the most elementary dataset, containing the excess returns on three \"Fama/French\" factors:\n",
    "\n",
    "https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_CSV.zip\n",
    "\n",
    "These returns were originally used in Fama and French (1992), for a very brief introduction see the Wikipedia page on the <a href=\"https://en.wikipedia.org/wiki/Fama%E2%80%93French_three-factor_model\">Fama-French three-factor model</a>.\n",
    "\n",
    "The data set contains the following monthly returns, and their annual accumulated versions:\n",
    "\n",
    "- <b><tt>RF</tt></b>: the nominal \"risk-free\" rate, equivalent to the yield on the U.S. one-month Treasury security\n",
    "\n",
    "- <b><tt>Mkt-RF</tt></b>: the excess return on a broadly constructed U.S. stock portfolio, net of the risk-free rate\n",
    "\n",
    "- <b><tt>SMB</tt></b>: the excess return on a portfolio of small U.S. firms, net of the return on a portfolio of large U.S. firms\n",
    "\n",
    "- <b><tt>HML</tt></b>: the excess return on a portfolio of U.S. firms with high ratio of book valuation to market valuation, net of the return on a portfolio of U.S. firms with low ratio of book valuation to market valuation\n",
    "\n",
    "We will be using the risk-free rate and the return on the aggregate stock market, the latter constructed from <b><tt>Mkt-RF</tt></b> by adding back the risk-free rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a57ee",
   "metadata": {},
   "source": [
    "In our theory, the returns are real gross returns. The data are nominal monthly net returns, expressed in percent. Denote $t$ the quarter and $\\widetilde{r}_{t+1,j}$, $j=1,2,3$ the monthly returns in the given quarter $t+1$, collected in the Kenneth French database.\n",
    "\n",
    "We build the gross nominal quarterly return as\n",
    "\n",
    "$$ R_{t+1}^N = \\prod_{j=1}^3 \\left( 1 + \\frac{\\widetilde{r}_{t+1,j}}{100} \\right) $$\n",
    "\n",
    "and then deflate by\n",
    "\n",
    "$$ R_{t+1} = \\frac{ R_{t+1}^N}{1+\\pi_{t+1}}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf2a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data in ZIP format and extract the CSV file\n",
    "param = {}\n",
    "param['filename'] = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_CSV.zip'\n",
    "param['returns'] = ['Mkt-RF','SMB','HML','RF']\n",
    "\n",
    "result = requests.get(param['filename'])\n",
    "data_FF = pd.read_csv(BytesIO(result.content),compression='zip',header=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a93c8",
   "metadata": {},
   "source": [
    "The file contains both monthly and annual data, so we first need to extract the right rows, corresponding to monthly data (this may be easier to do manually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5513c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "# rename date column\n",
    "data_FF = data_FF.rename(columns={'Unnamed: 0':'date'})\n",
    "# drop non-numerical rows\n",
    "data_FF = data_FF[pd.to_numeric(data_FF['date'], errors='coerce').notnull()]\n",
    "# only select data corresponding to months, and create a year-month index YYYYMM\n",
    "data_FF['YYYYMM'] = pd.to_numeric(data_FF['date'])\n",
    "data_FF = data_FF[data_FF['YYYYMM'] > 192606]\n",
    "# convert returns columns into numerical values\n",
    "for f in param['returns']:\n",
    "    data_FF[f] = pd.to_numeric(data_FF[f])\n",
    "# create years and months identifiers\n",
    "data_FF['YYYY'] = data_FF['YYYYMM'] // 100\n",
    "data_FF['MM'] = data_FF['YYYYMM'] % 100\n",
    "# create the market return\n",
    "data_FF['Mkt'] = data_FF['Mkt-RF'].to_numpy() + data_FF['RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cba566",
   "metadata": {},
   "source": [
    "The monthly return data must be converted to quarterly data by multiplicative accumulation of monthly returns in corresponding quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6cdef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify odd initial and terminal months not corresponding to whole quarters\n",
    "init_year_months = sum(data_FF['YYYY'] == min(data_FF['YYYY']))\n",
    "end_year_months = sum(data_FF['YYYY'] == max(data_FF['YYYY']))\n",
    "# isolate months corresponding to whole quarters\n",
    "if end_year_months % 3 > 0:\n",
    "    d = data_FF.iloc[init_year_months % 3:-(end_year_months % 3),:].copy()\n",
    "else:\n",
    "    d = data_FF.iloc[init_year_months % 3:,:].copy()\n",
    "# create a quarter index for each month\n",
    "d['YYYYQ'] = d['YYYY']*10 + (d['MM']-1) // 3 + 1\n",
    "# aggregate monthly nominal returns into quarterly nominal returns, using the groupby function\n",
    "# returns are stored as net returns\n",
    "# d = d.groupby('YYYYQ', group_keys=False).apply(lambda grp: ((1+grp[['RF','Mkt']]/100).prod()-1), include_groups=False)\n",
    "d = d.groupby('YYYYQ', group_keys=False).apply(lambda grp: ((1+grp[['RF','Mkt']]/100).prod()-1))\n",
    "#d = d.drop(columns=['YYYYQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a84ef",
   "metadata": {},
   "source": [
    "Finally, we can merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a98568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataset from FRED with the returns data, only using overlapping quarters, using YYYYQ as the merging index\n",
    "data = pd.concat([d,data_C],axis=1,join=\"inner\")\n",
    "data['date'] = data.index//10 + ((data.index % 10)-1)/4\n",
    "\n",
    "# create real returns\n",
    "data['Mkt_real'] = (1+data['Mkt'])/(1+data['infl'])-1\n",
    "data['RF_real'] = (1+data['RF'])/(1+data['infl'])-1\n",
    "data['Mkt-RF_real'] = data['Mkt_real'] - data['RF_real']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285da8f-6c1f-4252-9ea2-67fb9846f7ab",
   "metadata": {},
   "source": [
    "## Generalized method of moments (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d30228-d330-44ca-83ef-cf671c3689fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>Mkt</th>\n",
       "      <th>PCEC</th>\n",
       "      <th>PCECC96</th>\n",
       "      <th>A794RX0Q048SBEA</th>\n",
       "      <th>PCECTPI</th>\n",
       "      <th>infl</th>\n",
       "      <th>gC</th>\n",
       "      <th>date</th>\n",
       "      <th>Mkt_real</th>\n",
       "      <th>RF_real</th>\n",
       "      <th>Mkt-RF_real</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYYQ</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19472</th>\n",
       "      <td>0.000900</td>\n",
       "      <td>-0.006465</td>\n",
       "      <td>160.031</td>\n",
       "      <td>1373.880</td>\n",
       "      <td>9555</td>\n",
       "      <td>11.649</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>1947.25</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.007005</td>\n",
       "      <td>-0.007308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19473</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>163.543</td>\n",
       "      <td>1378.358</td>\n",
       "      <td>9542</td>\n",
       "      <td>11.866</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>-0.001361</td>\n",
       "      <td>1947.50</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.017109</td>\n",
       "      <td>0.017447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19474</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>167.672</td>\n",
       "      <td>1378.796</td>\n",
       "      <td>9501</td>\n",
       "      <td>12.162</td>\n",
       "      <td>0.024945</td>\n",
       "      <td>-0.004297</td>\n",
       "      <td>1947.75</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>-0.022385</td>\n",
       "      <td>0.033847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19481</th>\n",
       "      <td>0.002302</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>170.372</td>\n",
       "      <td>1385.667</td>\n",
       "      <td>9510</td>\n",
       "      <td>12.297</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>1948.00</td>\n",
       "      <td>-0.015891</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>-0.007189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19482</th>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.113741</td>\n",
       "      <td>174.142</td>\n",
       "      <td>1401.789</td>\n",
       "      <td>9582</td>\n",
       "      <td>12.424</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>1948.25</td>\n",
       "      <td>0.102357</td>\n",
       "      <td>-0.007746</td>\n",
       "      <td>0.110102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20234</th>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.119431</td>\n",
       "      <td>19170.154</td>\n",
       "      <td>15781.367</td>\n",
       "      <td>46641</td>\n",
       "      <td>121.480</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>2023.75</td>\n",
       "      <td>0.114852</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.105538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.102034</td>\n",
       "      <td>19424.775</td>\n",
       "      <td>15856.867</td>\n",
       "      <td>46759</td>\n",
       "      <td>122.507</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>2024.00</td>\n",
       "      <td>0.092796</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.088032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20242</th>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>19682.699</td>\n",
       "      <td>15967.266</td>\n",
       "      <td>46972</td>\n",
       "      <td>123.275</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>2024.25</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.022315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20243</th>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.060370</td>\n",
       "      <td>19938.425</td>\n",
       "      <td>16113.035</td>\n",
       "      <td>47303</td>\n",
       "      <td>123.747</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>2024.50</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.046831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20244</th>\n",
       "      <td>0.011645</td>\n",
       "      <td>0.033138</td>\n",
       "      <td>20262.717</td>\n",
       "      <td>16278.452</td>\n",
       "      <td>47714</td>\n",
       "      <td>124.482</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>2024.75</td>\n",
       "      <td>0.027038</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0.021366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             RF       Mkt       PCEC    PCECC96  A794RX0Q048SBEA  PCECTPI  \\\n",
       "YYYYQ                                                                       \n",
       "19472  0.000900 -0.006465    160.031   1373.880             9555   11.649   \n",
       "19473  0.001200  0.018972    163.543   1378.358             9542   11.866   \n",
       "19474  0.002001  0.036693    167.672   1378.796             9501   12.162   \n",
       "19481  0.002302 -0.004967    170.372   1385.667             9510   12.297   \n",
       "19482  0.002502  0.113741    174.142   1401.789             9582   12.424   \n",
       "...         ...       ...        ...        ...              ...      ...   \n",
       "20234  0.013460  0.119431  19170.154  15781.367            46641  121.480   \n",
       "20241  0.013258  0.102034  19424.775  15856.867            46759  122.507   \n",
       "20242  0.013258  0.035713  19682.699  15967.266            46972  123.275   \n",
       "20243  0.013359  0.060370  19938.425  16113.035            47303  123.747   \n",
       "20244  0.011645  0.033138  20262.717  16278.452            47714  124.482   \n",
       "\n",
       "           infl        gC     date  Mkt_real   RF_real  Mkt-RF_real  \n",
       "YYYYQ                                                                \n",
       "19472  0.007961  0.012075  1947.25 -0.014312 -0.007005    -0.007308  \n",
       "19473  0.018628 -0.001361  1947.50  0.000338 -0.017109     0.017447  \n",
       "19474  0.024945 -0.004297  1947.75  0.011462 -0.022385     0.033847  \n",
       "19481  0.011100  0.000947  1948.00 -0.015891 -0.008702    -0.007189  \n",
       "19482  0.010328  0.007571  1948.25  0.102357 -0.007746     0.110102  \n",
       "...         ...       ...      ...       ...       ...          ...  \n",
       "20234  0.004108  0.006040  2023.75  0.114852  0.009314     0.105538  \n",
       "20241  0.008454  0.002530  2024.00  0.092796  0.004764     0.088032  \n",
       "20242  0.006269  0.004555  2024.25  0.029261  0.006946     0.022315  \n",
       "20243  0.003829  0.007047  2024.50  0.056325  0.009494     0.046831  \n",
       "20244  0.005940  0.008689  2024.75  0.027038  0.005672     0.021366  \n",
       "\n",
       "[311 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01587d6a-66c6-40ff-8b46-15ba29431016",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.43     \n",
    "mu  = 0.018     \n",
    "delta = 0.036 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5fb532-d335-4463-945d-c5912161809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_objective_disaster_bet_gam_fixed(par):\n",
    "    \n",
    "    psi, d1, d2, p = par[0], par[1], par[2], par[3]\n",
    "\n",
    "    ### ADDED CODE ###\n",
    "\n",
    "    P = np.array([[phi, 1 - phi - d1, d1], \n",
    "                  [1 - phi - d2, phi, d2],\n",
    "                  [0.5 - 0.5 * p, 0.5 - 0.5 * p, p]])\n",
    "\n",
    "    GAMMAC = np.array([[1 + mu + delta, 1 + mu - delta, psi * (1 + mu)], \n",
    "                       [1 + mu + delta, 1 + mu - delta, psi * (1 + mu)],\n",
    "                       [1 + mu + delta, 1 + mu - delta, psi * (1 + mu)]])\n",
    "    \n",
    "    GAMMAG = GAMMAC.copy()\n",
    "\n",
    "    S = bet * np.power(GAMMAC, -gam)\n",
    "\n",
    "    N = P.shape[0]\n",
    "    I = np.identity(N)\n",
    "    one = np.ones([N,1])\n",
    "    \n",
    "    # first compute the unconditional stationary distribution PII (assuming it is unique)\n",
    "    # unconditional stationary distribution is the eigenvector of P' associated\n",
    "    # with eigenvalue equal to 1 (the largest eigenvalue)\n",
    "    eigval, eigvec = np.linalg.eig(P.transpose())\n",
    "    idx = np.abs(eigval).argsort()\n",
    "    eigval = eigval[idx]\n",
    "    eigvec = eigvec[:,idx]\n",
    "    PII = eigvec[:,-1:] / sum(eigvec[:,-1])\n",
    "\n",
    "    # conditional gross risk-free rate (Nx1 vector)\n",
    "    Rf = 1 / ((P * S) @ one)\n",
    "    # unconditional gross risk-free rate, stored as a scalar\n",
    "    ERf = (Rf.transpose() @ PII).item()\n",
    "    \n",
    "    # recursive formula for the price-dividend ratio: q =  P*S*GAMMAG @ (q + 1)\n",
    "    # where * is elementwise multiplication, @ is matrix multiplication, 1 is an Nx1 vector of ones\n",
    "    # solution given by\n",
    "    # q = inv(I - P*S*GAMMAG) * (P*S*GAMMAG)*1\n",
    "\n",
    "    # solution for the infinite-horizon asset only valid\n",
    "    # if P*S*G has eigenvalues inside the unit circle\n",
    "    M = P * S * GAMMAG\n",
    "    eigval, eigvec = np.linalg.eig(M)\n",
    "    maxeig = max(eigval)\n",
    "\n",
    "    if (maxeig < 1):\n",
    "        # asset price (Nx1 vector)\n",
    "        q = np.linalg.inv(I - M) @ (M @ one)\n",
    "        # returns (NxN matrix of returns R(i,j)\n",
    "        R = ((1/q) @ (q.transpose()+1)) * GAMMAG\n",
    "        # conditional expected returns (Nx1 vector)\n",
    "        EtR = (R * P) @ one\n",
    "        # unconditional expected return\n",
    "        ER = (EtR.transpose() @ PII).item()\n",
    "        # excess returns, realized and expected\n",
    "        Re = R - np.tile(Rf,[1,N])\n",
    "        EtRe = EtR - Rf\n",
    "        ERe = ER - ERf\n",
    "    else:\n",
    "        q = (np.empty([N,1]))*np.nan\n",
    "        R = (np.empty([N,N]))*np.nan\n",
    "        EtR = (np.empty([N,1]))*np.nan\n",
    "        ER = np.nan\n",
    "        Re = (np.empty([N,N]))*np.nan\n",
    "        EtRe = (np.empty([N,1]))*np.nan\n",
    "        ERe = np.nan\n",
    "\n",
    "    ### ORIGINAL CODE ###\n",
    "    \n",
    "    # moment conditions\n",
    "    f1 = pd.Series([ERf - np.mean(1 + data['RF_real'])])\n",
    "    \n",
    "    \n",
    "    VarRf = ((Rf.transpose() - ERf) ** 2 @ PII).item()\n",
    "    f2 = pd.Series([VarRf - np.var(1 + data['RF_real'])])\n",
    "    \n",
    "    \n",
    "    f3 = pd.Series([ER - np.mean(data['Mkt_real'])])\n",
    "    \n",
    "\n",
    "    EEtRe = (EtRe.transpose() @ PII).item()\n",
    "    VarEtRe = ((EtRe.transpose() - EEtRe) ** 2 @ PII).item()\n",
    "\n",
    "    EtRe2 = (Re ** 2 * P) @ one  \n",
    "    VartRe = EtRe2 - EtRe ** 2\n",
    "    EVartRe = (VartRe.transpose() @ PII).item()\n",
    "\n",
    "    VarRe = EVartRe + VarEtRe\n",
    "    \n",
    "    f4 = pd.Series([VarRe - np.var(data['Mkt-RF_real'])])\n",
    "    \n",
    "    \n",
    "    # number of data points\n",
    "    T = len(f1)\n",
    "    \n",
    "    # weighting matrix - identity matrix chosen for simplicity\n",
    "    W = np.identity(4) # SET FOR INITIAL RESULTS\n",
    "    # W = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0.01, 0], [0, 0, 0, 1]]) # SET FOR DOWNWEIGHTING f3\n",
    "    \n",
    "    # f is the T*M matrix of data for the moment conditions\n",
    "    f = np.array([f1,f2,f3,f4]).transpose()\n",
    "    \n",
    "    # compute and return the GMM criterion function\n",
    "    g = sum(f).transpose()/T\n",
    "    \n",
    "    return g.transpose()@W@g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e20bb99-741b-4657-a317-7df88a52c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bet and gam to iterate through\n",
    "bet_lst = np.arange(0, 1.1, 0.1).tolist()\n",
    "gam_lst = np.arange(0, 11, 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0c3747-5b50-44c9-ae62-b54e677907bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3c986-e1d2-418f-8c82-72481ee7ab4e",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e660565c-cd24-4422-a851-bd2887a8c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bet: 0.6000000000000001, gam: 0, psi: 0.7645760639590922, d1: 0.024996716673687077, d2: 0.025393521300485396, p: 0.0001652430858490285\n",
      "bet: 0.6000000000000001, gam: 9, psi: 0.6963837658533261, d1: 0.05172341724566351, d2: 0.08057972904375449, p: 0.0315970573987443\n",
      "bet: 0.7000000000000001, gam: 0, psi: 0.7010647102470347, d1: 0.024745172000960568, d2: 0.027066449260507976, p: 0.00024310693322758726\n",
      "bet: 0.8, gam: 8, psi: 0.6554453163989522, d1: 0.012517441521696274, d2: 0.017507736860628703, p: 0.0350405854952667\n",
      "bet: 0.9, gam: 10, psi: 0.7917543646695782, d1: 0.024584714553936765, d2: 0.05639964484604071, p: 2.7843196119782955e-05\n",
      "bet: 1.0, gam: 1, psi: 0.8393749988825061, d1: 0.024149999979489516, d2: 0.025050000113056192, p: 3.124999821204522e-05\n",
      "bet: 1.0, gam: 5, psi: 0.7100332069940407, d1: 0.019691637047806743, d2: 0.02622383886813628, p: 0.0001887839340000588\n",
      "bet: 1.0, gam: 9, psi: 0.8263553705950404, d1: 0.013115345003117541, d2: 0.04856876862782025, p: 0.0001285072311641523\n",
      "bet: 1.0, gam: 10, psi: 0.8532082088243123, d1: 0.009301826119465582, d2: 0.06089279399697045, p: 0.00751559876309725\n"
     ]
    }
   ],
   "source": [
    "gmm_dict = {}\n",
    "for bet in bet_lst:\n",
    "    for gam in gam_lst:\n",
    "        par = [0.85, 0.024, 0.024, 0]\n",
    "        xopt = optimize.fmin(GMM_objective_disaster_bet_gam_fixed, par, xtol=1e-12, disp=False)\n",
    "        psi, d1, d2, p = xopt[0], xopt[1], xopt[2], xopt[3]\n",
    "        # Only print reasonable parameter values\n",
    "        if (psi < 0.982 / 1.018) and (psi >= 0.65) and (d1 >= 0) and (d2 >= 0) and (p >= 0) and (d1 <= 0.081) and (d2 <= 0.081) and (p <= 1) and (d2 > d1):\n",
    "            print(f\"bet: {bet}, gam: {gam}, psi: {psi}, d1: {d1}, d2: {d2}, p: {p}\")\n",
    "            # Store result in dictionary\n",
    "            gmm_dict[(bet, gam)] = (psi, d1, d2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ec7085-debd-4c83-9601-4b8386a7b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Mehra_Prescott(model):\n",
    "    \n",
    "    S = model[\"SDF\"]\n",
    "    P = model[\"P\"]\n",
    "    GAMMAG = model[\"GAMMAG\"]\n",
    "    \n",
    "    N = P.shape[0]\n",
    "    I = np.identity(N)\n",
    "    one = np.ones([N,1])\n",
    "    \n",
    "    # first compute the unconditional stationary distribution PII (assuming it is unique)\n",
    "    # unconditional stationary distribution is the eigenvector of P' associated\n",
    "    # with eigenvalue equal to 1 (the largest eigenvalue)\n",
    "    eigval,eigvec = np.linalg.eig(P.transpose())\n",
    "    idx = np.abs(eigval).argsort()\n",
    "    eigval = eigval[idx]\n",
    "    eigvec = eigvec[:,idx]\n",
    "    PII = eigvec[:,-1:] /sum( eigvec[:,-1])\n",
    "\n",
    "    # conditional gross risk-free rate (Nx1 vector)\n",
    "    # Rf = 1 / (np.multiply(P,S)*one)\n",
    "    Rf = 1 / ((P * S) @ one)\n",
    "    # unconditional gross risk-free rate, stored as a scalar\n",
    "    ERf = (Rf.transpose() @ PII).item()\n",
    "    \n",
    "    # recursive formula for the price-dividend ratio: q =  P*S*GAMMAG @ (q + 1)\n",
    "    # where * is elementwise multiplication, @ is matrix multiplication, 1 is an Nx1 vector of ones\n",
    "    # solution given by\n",
    "    # q = inv(I - P*S*GAMMAG) * (P*S*GAMMAG)*1\n",
    "\n",
    "    # solution for the infinite-horizon asset only valid\n",
    "    # if P*S*G has eigenvalues inside the unit circle\n",
    "    M = P*S*GAMMAG\n",
    "    eigval,eigvec = np.linalg.eig(M)\n",
    "    maxeig = max(eigval)\n",
    "\n",
    "    if (maxeig < 1):\n",
    "        # asset price (Nx1 vector)\n",
    "        q = np.linalg.inv(I - M) @ (M @ one)\n",
    "        # returns (NxN matrix of returns R(i,j)\n",
    "        R = ((1/q) @ (q.transpose()+1)) * GAMMAG\n",
    "        # conditional expected returns (Nx1 vector)\n",
    "        EtR = (R * P) @ one\n",
    "        # unconditional expected return\n",
    "        ER = (EtR.transpose() @ PII).item()\n",
    "        # excess returns, realized and expected\n",
    "        Re = R - np.tile(Rf,[1,N])\n",
    "        EtRe = EtR - Rf\n",
    "        ERe = ER - ERf\n",
    "    else:\n",
    "        q = (np.empty([N,1]))*np.nan\n",
    "        R = (np.empty([N,N]))*np.nan\n",
    "        EtR = (np.empty([N,1]))*np.nan\n",
    "        ER = np.nan\n",
    "        Re = (np.empty([N,N]))*np.nan\n",
    "        EtRe = (np.empty([N,1]))*np.nan\n",
    "        ERe = np.nan\n",
    "\n",
    "    sol = {\"PII\": PII, \"Rf\": Rf, \"ERf\": ERf, \"q\": q, \"R\": R, \"EtR\": EtR, \"ER\": ER, \"Re\": Re, \"EtRe\": EtRe, \"ERe\": ERe}\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96a540-d4da-402c-98b1-f76a6c9b340b",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e0d5cb7-38da-45f3-a9ed-de00310b6763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6000000000000001,0): 0.6666666666666663, -4.440892098500626e-16\n",
      "(0.6000000000000001,9): -0.24660169177174962, 0.258064647219718\n",
      "(0.7000000000000001,0): 0.42857142857142816, -2.220446049250313e-16\n",
      "(0.8,8): -0.023758467875154565, 0.03552120641951362\n",
      "(0.9,10): -0.06751903967265405, 0.08024973004558744\n",
      "(1.0,1): 0.012114906707942685, 0.0019448479525876472\n",
      "(1.0,5): -0.024423127766000863, 0.03645347190662618\n",
      "(1.0,9): -0.018298609996736492, 0.030882335919088733\n",
      "(1.0,10): -0.010097289255448394, 0.022649153087565543\n"
     ]
    }
   ],
   "source": [
    "# GMM ERf and ERe\n",
    "for key in gmm_dict:\n",
    "\n",
    "    model = {\"PHI\": 0.43, \"MU\": 0.018, \"DELTA\": 0.036}\n",
    "\n",
    "    model[\"psi\"], model[\"d1\"], model[\"d2\"], model[\"p\"] = gmm_dict[key][0], gmm_dict[key][1], gmm_dict[key][2], gmm_dict[key][3]\n",
    "    \n",
    "    model[\"P\"] = np.array([[model[\"PHI\"], 1 - model[\"PHI\"] - model[\"d1\"], model[\"d1\"]], \n",
    "                           [1 - model[\"PHI\"] - model[\"d2\"], model[\"PHI\"], model[\"d2\"]],\n",
    "                           [0.5 - 0.5 * model[\"p\"], 0.5 - 0.5 * model[\"p\"], model[\"p\"]]])\n",
    "    \n",
    "    model[\"GAMMAC\"] = np.array([[1 + model[\"MU\"] + model[\"DELTA\"], 1 + model[\"MU\"] - model[\"DELTA\"], model[\"psi\"] * (1 + model[\"MU\"])], \n",
    "                                [1 + model[\"MU\"] + model[\"DELTA\"], 1 + model[\"MU\"] - model[\"DELTA\"], model[\"psi\"] * (1 + model[\"MU\"])],\n",
    "                                [1 + model[\"MU\"] + model[\"DELTA\"], 1 + model[\"MU\"] - model[\"DELTA\"], model[\"psi\"] * (1 + model[\"MU\"])]])\n",
    "    \n",
    "    model[\"GAMMAG\"] = model[\"GAMMAC\"].copy()\n",
    "\n",
    "    bet, gam = key[0], key[1]\n",
    "    model[\"SDF\"] = bet * np.power(model[\"GAMMAC\"], -gam)\n",
    "    sol = solve_Mehra_Prescott(model)\n",
    "\n",
    "    ERf = sol[\"ERf\"] - 1\n",
    "    ERe = sol[\"ERe\"]\n",
    "    \n",
    "    print(f\"({bet},{gam}): {ERf}, {ERe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50cecb92-fd96-428d-8b46-38a1830dd270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6000000000000001,0): 0.6666666666666665, 0.0\n",
      "(0.6000000000000001,9): 0.7285727659775765, 0.04637161419880842\n",
      "(0.7000000000000001,0): 0.4285714285714284, 2.220446049250313e-16\n",
      "(0.8,8): 0.30360361152125814, 0.031336781616828624\n",
      "(0.9,10): 0.14275694915873793, 0.040752672942820256\n",
      "(1.0,1): 0.012590703662050284, nan\n",
      "(1.0,5): 0.043828612246280985, 0.013350375328413211\n",
      "(1.0,9): 0.037143659586545974, 0.032070461511460424\n",
      "(1.0,10): 0.028481254242864074, 0.0380014219922975\n"
     ]
    }
   ],
   "source": [
    "# Empirical ERf and ERe\n",
    "for key in gmm_dict:\n",
    "\n",
    "    model = {\"PHI\": 0.43, \"MU\": 0.018, \"DELTA\": 0.036}\n",
    "\n",
    "    model[\"psi\"], model[\"d1\"], model[\"d2\"], model[\"p\"] = 0.85, 0.024, 0.024, 0\n",
    "    \n",
    "    model[\"P\"] = np.array([[model[\"PHI\"], 1 - model[\"PHI\"] - model[\"d1\"], model[\"d1\"]], \n",
    "                           [1 - model[\"PHI\"] - model[\"d2\"], model[\"PHI\"], model[\"d2\"]],\n",
    "                           [0.5 - 0.5 * model[\"p\"], 0.5 - 0.5 * model[\"p\"], model[\"p\"]]])\n",
    "    \n",
    "    model[\"GAMMAC\"] = np.array([[1 + model[\"MU\"] + model[\"DELTA\"], 1 + model[\"MU\"] - model[\"DELTA\"], model[\"psi\"] * (1 + model[\"MU\"])], \n",
    "                                [1 + model[\"MU\"] + model[\"DELTA\"], 1 + model[\"MU\"] - model[\"DELTA\"], model[\"psi\"] * (1 + model[\"MU\"])],\n",
    "                                [1 + model[\"MU\"] + model[\"DELTA\"], 1 + model[\"MU\"] - model[\"DELTA\"], model[\"psi\"] * (1 + model[\"MU\"])]])\n",
    "    \n",
    "    model[\"GAMMAG\"] = model[\"GAMMAC\"].copy()\n",
    "\n",
    "    bet, gam = key[0], key[1]\n",
    "    model[\"SDF\"] = bet * np.power(model[\"GAMMAC\"], -gam)\n",
    "    sol = solve_Mehra_Prescott(model)\n",
    "\n",
    "    ERf = sol[\"ERf\"] - 1\n",
    "    ERe = sol[\"ERe\"]\n",
    "    \n",
    "    print(f\"({bet},{gam}): {ERf}, {ERe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c85dd-0149-4fa4-bd84-215a48e9e33c",
   "metadata": {},
   "source": [
    "## Examining moment condition errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d88924-8c48-44c4-a3a7-a2ee75e8c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6000000000000001, 0): Average moment condition errors (g, in %): 66.47194, -0.00468, 164.37021,  -0.00000\n",
      "(0.6000000000000001, 9): Average moment condition errors (g, in %): -24.85490, 1.41568, 98.84984,  0.90338\n",
      "(0.7000000000000001, 0): Average moment condition errors (g, in %): 42.66242, -0.00468, 140.56068,  0.00000\n",
      "(0.8, 8): Average moment condition errors (g, in %): -2.57057, 0.16004, 98.87981,  -0.61548\n",
      "(0.9, 10): Average moment condition errors (g, in %): -6.94663, 0.86122, 98.97661,  -0.11913\n",
      "(1.0, 1): Average moment condition errors (g, in %): 1.01676, -0.00305, 99.10952,  -0.47288\n",
      "(1.0, 5): Average moment condition errors (g, in %): -2.63704, 0.01948, 98.90657,  -0.22885\n",
      "(1.0, 9): Average moment condition errors (g, in %): -2.02459, 0.17318, 98.96191,  -0.43361\n",
      "(1.0, 10): Average moment condition errors (g, in %): -1.20446, 0.26345, 98.95873,  -0.49361\n"
     ]
    }
   ],
   "source": [
    "for key in gmm_dict:\n",
    "\n",
    "    bet, gam = key[0], key[1]\n",
    "\n",
    "    psi, d1, d2, p = gmm_dict[key][0], gmm_dict[key][1], gmm_dict[key][2], gmm_dict[key][3]\n",
    "\n",
    "    P = np.array([[phi, 1 - phi - d1, d1], \n",
    "                  [1 - phi - d2, phi, d2],\n",
    "                  [0.5 - 0.5 * p, 0.5 - 0.5 * p, p]])\n",
    "\n",
    "    GAMMAC = np.array([[1 + mu + delta, 1 + mu - delta, psi * (1 + mu)], \n",
    "                       [1 + mu + delta, 1 + mu - delta, psi * (1 + mu)],\n",
    "                       [1 + mu + delta, 1 + mu - delta, psi * (1 + mu)]])\n",
    "    \n",
    "    GAMMAG = GAMMAC.copy()\n",
    "\n",
    "    S = bet * np.power(GAMMAC, -gam)\n",
    "\n",
    "    N = P.shape[0]\n",
    "    I = np.identity(N)\n",
    "    one = np.ones([N,1])\n",
    "    \n",
    "    # first compute the unconditional stationary distribution PII (assuming it is unique)\n",
    "    # unconditional stationary distribution is the eigenvector of P' associated\n",
    "    # with eigenvalue equal to 1 (the largest eigenvalue)\n",
    "    eigval, eigvec = np.linalg.eig(P.transpose())\n",
    "    idx = np.abs(eigval).argsort()\n",
    "    eigval = eigval[idx]\n",
    "    eigvec = eigvec[:,idx]\n",
    "    PII = eigvec[:,-1:] / sum(eigvec[:,-1])\n",
    "\n",
    "    # conditional gross risk-free rate (Nx1 vector)\n",
    "    Rf = 1 / ((P * S) @ one)\n",
    "    # unconditional gross risk-free rate, stored as a scalar\n",
    "    ERf = (Rf.transpose() @ PII).item()\n",
    "    \n",
    "    # recursive formula for the price-dividend ratio: q =  P*S*GAMMAG @ (q + 1)\n",
    "    # where * is elementwise multiplication, @ is matrix multiplication, 1 is an Nx1 vector of ones\n",
    "    # solution given by\n",
    "    # q = inv(I - P*S*GAMMAG) * (P*S*GAMMAG)*1\n",
    "\n",
    "    # solution for the infinite-horizon asset only valid\n",
    "    # if P*S*G has eigenvalues inside the unit circle\n",
    "    M = P * S * GAMMAG\n",
    "    eigval, eigvec = np.linalg.eig(M)\n",
    "    maxeig = max(eigval)\n",
    "\n",
    "    if (maxeig < 1):\n",
    "        # asset price (Nx1 vector)\n",
    "        q = np.linalg.inv(I - M) @ (M @ one)\n",
    "        # returns (NxN matrix of returns R(i,j)\n",
    "        R = ((1/q) @ (q.transpose()+1)) * GAMMAG\n",
    "        # conditional expected returns (Nx1 vector)\n",
    "        EtR = (R * P) @ one\n",
    "        # unconditional expected return\n",
    "        ER = (EtR.transpose() @ PII).item()\n",
    "        # excess returns, realized and expected\n",
    "        Re = R - np.tile(Rf,[1,N])\n",
    "        EtRe = EtR - Rf\n",
    "        ERe = ER - ERf\n",
    "    else:\n",
    "        q = (np.empty([N,1]))*np.nan\n",
    "        R = (np.empty([N,N]))*np.nan\n",
    "        EtR = (np.empty([N,1]))*np.nan\n",
    "        ER = np.nan\n",
    "        Re = (np.empty([N,N]))*np.nan\n",
    "        EtRe = (np.empty([N,1]))*np.nan\n",
    "        ERe = np.nan\n",
    "    \n",
    "    # construct the moment conditions\n",
    "    f1 = pd.Series([ERf - np.mean(1 + data['RF_real'])])\n",
    "    \n",
    "    \n",
    "    VarRf = ((Rf.transpose() - ERf) ** 2 @ PII).item()\n",
    "    f2 = pd.Series([VarRf - np.var(1 + data['RF_real'])])\n",
    "    \n",
    "    \n",
    "    f3 = pd.Series([ER - np.mean(data['Mkt_real'])])\n",
    "    \n",
    "\n",
    "    EEtRe = (EtRe.transpose() @ PII).item()\n",
    "    VarEtRe = ((EtRe.transpose() - EEtRe) ** 2 @ PII).item()\n",
    "\n",
    "    EtRe2 = (Re ** 2 * P) @ one  \n",
    "    VartRe = EtRe2 - EtRe ** 2\n",
    "    EVartRe = (VartRe.transpose() @ PII).item()\n",
    "\n",
    "    VarRe = EVartRe + VarEtRe\n",
    "    \n",
    "    f4 = pd.Series([VarRe - np.var(data['Mkt-RF_real'])])\n",
    "    \n",
    "    \n",
    "    T = len(f1)\n",
    "    f = np.array([f1,f2,f3,f4]).transpose()\n",
    "    g = sum(f)/T\n",
    "    \n",
    "    print(f'({bet}, {gam}): Average moment condition errors (g, in %): {(g[0]*100):.5f}, {(g[1]*100):.5f}, {(g[2]*100):.5f},  {(g[3]*100):.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
